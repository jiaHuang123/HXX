%
% ---------------------------------------------------------------
% Copyright (C) 2012-2018 Gang Li
% ---------------------------------------------------------------
%
% This work is the default powerdot-tuliplab style test file and may be
% distributed and/or modified under the conditions of the LaTeX Project Public
% License, either version 1.3 of this license or (at your option) any later
% version. The latest version of this license is in
% http://www.latex-project.org/lppl.txt and version 1.3 or later is part of all
% distributions of LaTeX version 2003/12/01 or later.
%
% This work has the LPPL maintenance status "maintained".
%
% This Current Maintainer of this work is Gang Li.
%
%

\documentclass[
 size=14pt,
 paper=smartboard,  %a4paper, smartboard, screen
 mode=present, 		%present, handout, print
 display=slides, 	% slidesnotes, notes, slides
 style=tuliplab,  	% TULIP Lab style
 pauseslide,
 fleqn,leqno]{powerdot}


\usepackage{cancel}
\usepackage{caption}
\usepackage{stackengine}
\usepackage{smartdiagram}
\usepackage{attrib}
\usepackage{amssymb}
\usepackage{amsmath} 
\usepackage{amsthm} 
\usepackage{mathtools}
\usepackage{rotating}
\usepackage{graphicx}
\usepackage{boxedminipage}
\usepackage{rotate}
\usepackage{calc}
\usepackage[absolute]{textpos}
\usepackage{psfrag,overpic}
\usepackage{fouriernc}
\usepackage{pstricks,pst-3d,pst-grad,pstricks-add,pst-text,pst-node,pst-tree}
\usepackage{moreverb,epsfig,subfigure}
\usepackage{color}
\usepackage{booktabs}
\usepackage{etex}
\usepackage{breqn}
\usepackage{multirow}
\usepackage{natbib}
\usepackage{bibentry}
\usepackage{gitinfo2}
\usepackage{siunitx}
\usepackage{nicefrac}
%\usepackage{geometry}
%\geometry{verbose,letterpaper}
\usepackage{media9}
\usepackage{animate}
%\usepackage{movie15}
\usepackage{auto-pst-pdf}

\usepackage{breakurl}
\usepackage{fontawesome}
\usepackage{xcolor}
\usepackage{multicol}



\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\usepackage{dtk-logos}
\usepackage{tikz}
\usepackage{adigraph}
%\usepackage{tkz-graph}
\usepackage{hyperref}
%\usepackage{ulem}
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{fontawesome}


\usepackage{todonotes}
% \usepackage{pst-rel-points}
\usepackage{animate}
\usepackage{fontawesome}

\usepackage{listings}
\lstset{frameround=fttt,
frame=trBL,
stringstyle=\ttfamily,
backgroundcolor=\color{yellow!20},
basicstyle=\footnotesize\ttfamily}
\lstnewenvironment{code}{
\lstset{frame=single,escapeinside=`',
backgroundcolor=\color{yellow!20},
basicstyle=\footnotesize\ttfamily}
}{}


\usepackage{hyperref}
\hypersetup{ % TODO: PDF meta Data
  pdftitle={Presentation Title},
  pdfauthor={Gang Li},
  pdfpagemode={FullScreen},
  pdfborder={0 0 0}
}


% \usepackage{auto-pst-pdf}
% package to show source code

\definecolor{LightGray}{rgb}{0.9,0.9,0.9}
\newlength{\pixel}\setlength\pixel{0.000714285714\slidewidth}
\setlength{\TPHorizModule}{\slidewidth}
\setlength{\TPVertModule}{\slideheight}
\newcommand\highlight[1]{\fbox{#1}}
\newcommand\icite[1]{{\footnotesize [#1]}}

\newcommand\twotonebox[2]{\fcolorbox{pdcolor2}{pdcolor2}
{#1\vphantom{#2}}\fcolorbox{pdcolor2}{white}{#2\vphantom{#1}}}
\newcommand\twotoneboxo[2]{\fcolorbox{pdcolor2}{pdcolor2}
{#1}\fcolorbox{pdcolor2}{white}{#2}}
\newcommand\vpspace[1]{\vphantom{\vspace{#1}}}
\newcommand\hpspace[1]{\hphantom{\hspace{#1}}}
\newcommand\COMMENT[1]{}

\newcommand\placepos[3]{\hbox to\z@{\kern#1
        \raisebox{-#2}[\z@][\z@]{#3}\hss}\ignorespaces}

\renewcommand{\baselinestretch}{1.2}


\newcommand{\draftnote}[3]{
	\todo[author=#2,color=#1!30,size=\footnotesize]{\textsf{#3}}	}
% TODO: add yourself here:
%
\newcommand{\gangli}[1]{\draftnote{blue}{GLi:}{#1}}
\newcommand{\shaoni}[1]{\draftnote{green}{sn:}{#1}}
\newcommand{\gliMarker}
	{\todo[author=GLi,size=\tiny,inline,color=blue!40]
	{Gang Li has worked up to here.}}
\newcommand{\snMarker}
	{\todo[author=Sn,size=\tiny,inline,color=green!40]
	{Shaoni has worked up to here.}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% title
% TODO: Customize to your Own Title, Name, Address
%
\title{Tweet Sentiment Extraction}
\author{
Jia Huang
\\
\\Xi'an Shiyou University
%\\Deakin University
\\Chinese Academy of Sciences
%\\ \today
}
%\date{\gitCommitterDate}


% Customize the setting of slides
\pdsetup{
% TODO: Customize the left footer, and right footer
rf=\href{http://www.tulip.org.au}{
Last Changed by: \textsc{\gitCommitterName}\ \gitVtagn-\gitAbbrevHash\ (\gitAuthorDate)
},
cf={San Francisco Crime classification},
}


\begin{document}

\maketitle

%\begin{slide}{Overview}
%\tableofcontents[content=sections]
%\end{slide}


%%==========================================================================================
%%
\begin{slide}[toc=,bm=]{Overview}
\tableofcontents[content=currentsection,type=1]
\end{slide}
%%
%%==========================================================================================


\section{Project Overview}


%%==========================================================================================
%%
\begin{slide}{Project Background And Purpose}
\begin{center}
\twotonebox{\rotatebox{95}{Defn}}{\parbox{.89\textwidth}
{
  \begin{itemize}
    \item Background
    \\With all of the tweets circulating every second it is hard 
    to tell whether the sentiment behind a specific tweet will impact 
    a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is 
    important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description?
    \item Purpose
    \\In this competition we've extracted support phrases from Figure Eight's Data
     for Everyone platform. The dataset is titled Sentiment Analysis: Emotion in Text tweets
      with existing sentiment labels, used here under creative commons attribution 4.0. international licence. Your objective in this 
      competition is to construct a model that can do the same - look at the labeled sentiment for a given tweet and figure out what
       word or phrase best supports it.
    \end{itemize}
}}

\end{center}
\bigskip
\begin{center}
\begin{tabular}{c| c c c c }
\toprule
\midrule

\bottomrule
\end{tabular}
\end{center}
\bigskip

%%==========================================================================================
\begin{note}
First, I will introduce the problem definition.
In the real life,
a teacher may be interested in the characteristics that
make one student obvious different from others.
Or,
NBA sports coaches would prefer to
know the advantages and disadvantages of one player.
Here, the player can be regarded as a query object.

For example, team A has five players,
each player has four features.
The NBA sports coaches may want to know the features of
player $1$ that are different from others.

The above example can be seen as outlying aspects mining.
The main purpose of outlying aspects mining is to identify
the outstanding features of the query object.
\end{note}
%%==========================================================================================

\end{slide}
%%
%%==========================================================================================


%%
%%==========================================================================================


\section{Data Pre-Processing}


%%==========================================================================================
%%
\begin{slide}{Date Processing}
%Related Work - Outlying Aspects Mining
Two data sets were given during the match: train.csv 
and test.csv.Train.csv data were used to construct the model and 
to predict test.csv data.
Now let's take a look at the training data provided by this 
competition, do some exploratory data analysis work, and learn more about
 the content of this training set.~\\
 The data sets train.csv and test.csv are respectively 27408 and 3534 pieces 
 of data.The data is described in terms of four attributes.

\bigskip
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\textwidth]{kaggle/01.1.eps}
  \caption{}
\end{figure}




%%==========================================================================================
\begin{note}
Let me introduce two existing methods:
Feature selection and score-and-search.

For feature selection,
the query point can be regarded as positive class and
the rest of the data can be regarded as negative class,
selected the features that best distinguish the two classes.

The advantages of this method are easy to operate,
and it's able to resolve dimensionality bias.
However, it has some drawbacks.
Firstly,
positive and negative classes are Not balanced,
secondly,
it can't quantify the outlying degree correctly.
Most importantly,
it doesn't identify group outlying aspects.
\end{note}
%%==========================================================================================

\end{slide}
%%
%%==========================================================================================

%%
%%==========================================================================================
\begin{slide}{Feature Item}
  As you can see from the table above, the four feature
  items in the training set are textID, Text, and selected_text sentiment.
  ~\\
  ~\\
  \bigskip
  \begin{itemize}
    \item textID
    \begin{itemize}
      \item Write the ID of the comment.
    \end{itemize}
    \item Text
    \begin{itemize}
      \item The specific content of the comment.
    \end{itemize}
    \item Selected_text
    \begin{itemize}
      \item Are the keywords that we have chosen to 
      judge the emotional state of the comment.
    \end{itemize}
    \item Sentiment
    \begin{itemize}
      \item The emotional polarity of the sentence.
    \end{itemize}
  \end{itemize}
\end{slide}

%%
%%==========================================================================================
\begin{slide}{Features Item}
  \begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{kaggle/01.3.eps}
  \end{figure}
  
  \bigskip
  There are three types of sentence emotional polarity.Neurtal
   indicates that the sentence is emotionally neutral, positive
    means the comment is positive, and negative means the 
    comment is negative.
\end{slide}
%%
%%==================================================================





%%==========================================================================================

\section{Constructing Dataset Generator}

%%==========================================================================================
%%
\begin{slide}{Similarity}
  Look at the Jaccard similarity between Text and selected_text.
  \bigskip
  \begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{kaggle/1.8.eps}
  \end{figure}
\end{slide}
%%
%%===========================================================================================



%%
%%=============================================================================================
\begin{slide}[toc=,bm=]{}

\begin{figure}[htbp]
  \centering
  \begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{kaggle/1.1.eps}
    \vspace{0.4em}
    \caption{ }
  \end{minipage}
  \begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{kaggle/1.2.eps}
    \vspace{0.4em}
    \caption{}
  \end{minipage}
  \begin{minipage}[t]{0.48\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{kaggle/1.3.eps}
    \vspace{0.4em}
    \caption{}
  \end{minipage}
\end{figure}

The 2,323 copies are duplicates and we need to delete them.
We will also evaluate the position of the data points using the coordinates.
%%==========================================================================================
\begin{note}
In conclusion,
we firstly formalized the problem of
group outlying aspects mining,

Then proposed a novel method GOAM algorithm to address the problem of
group outlying aspects mining,
and the proposed method use pruning to reduce time complexity
while identifying the suitable set of outlying features for the interested group.

Thank you and any question?
\end{note}
%%==========================================================================================

\end{slide}
%%
%%==========================================================================================

\begin{slide}{Feature Analysis}
  There are also some wrong locations in the data set. After analysis, we 
  found a total of 67 wrong messages, which also means that we cannot use
   these 67 wrong messages.
  \begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{kaggle/6.1.eps}
  \end{figure}


\end{slide}
%%
%%===========================================================================================



%%
%%========================================================================

\begin{slide}{Dates \& Day of the week}
  These variables are distributed uniformly between 1/1/2003 to 5/13/2015 (and Monday to Sunday) and split between the training and the testing dataset as mentioned before. We did not notice any anomalies on these variables.
  The median frequency of incidents is 389 per day with a standard deviation of 48.51.
  Also, there is no significant deviation of incidents frequency 
  throughout the week. Thus we do not expect this variable to play a 
  significant role in the prediction.


  \begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{kaggle/7.1.eps}
      \vspace{0.4em}
      \caption{Dates and Day of the Week}
    \end{minipage}
    \begin{minipage}[t]{0.48\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{kaggle/8.1.eps}
      \vspace{0.4em}
      \caption{Per Weekday}
    \end{minipage}
  \end{figure}
\end{slide}

%%
%%%%===============================================================

%%
%%===================================================================



\begin{slide}{Category \& Police District}
  There are 39 discrete categories that the police department file the incidents with the most common being 
  Larceny/Theft (19.91\%), Non/Criminal (10.50\%), and Assault(8.77\%).
  There are significant differences between the different districts of the City with the Southern district 
  having the most incidents (17.87\%) followed by Mission (13.67\%) and Northern (12.00\%).
  \begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
      \centering
      \includegraphics[width=0.7\textwidth]{kaggle/9.eps}
      \vspace{0.4em}
      \caption{Category}
    \end{minipage}
    \begin{minipage}[t]{0.48\textwidth}
      \centering
      \includegraphics[width=0.7\textwidth]{kaggle/10.eps}
      \vspace{0.4em}
      \caption{Police District}
    \end{minipage}
  \end{figure}
\end{slide}

%%
%%=========================================================================

%%
%%==========================================================================


\begin{slide}{X \& Y}
  \begin{itemize}
  \item Address
Address, as a text field, requires advanced techniques to use 
it for the prediction. Instead in this project, we will use it to 
extract if the incident has happened on the road or in a building block.
\item X - Longitude Y - Latitude
We have tested that the coordinates belong inside the
 boundaries of the city. Although longitude does not contain any
  outliers, latitude includes some 90o values which correspond to the North Pole.
\end{itemize}
\end{slide}

%%
%%==============================================================================

\section{Feature Selection} 

%%===========================================================================================
%%

%%
%%========================================================================================

\begin{slide}{Feature Engineering}
  Then, we created additional features. More specifically:
\begin{itemize}
  \item From the ‘Dates’ field, we extracted the Day, the Month, the
   Year, the Hour, the Minute, the Weekday, and the number of days 
   since the first day in the data.

  \item From the ‘Address’ field we extracted if the incident has taken
   place in a crossroad or on a building block.
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{kaggle/14.eps}
\end{figure}
  
\end{slide}


%%
%%==================================================================================




%%
%%==============================================================================




%%==========================================================================================
%%



% TODO: Contact Page

\end{document}

\endinput
